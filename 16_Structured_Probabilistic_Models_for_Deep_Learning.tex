\chapter{Structured Probabilistic Models for Deep Learning}

\textit{结构化概率模型}(Structured Probabilistic Models)是一种使用图的形式描述随机变量间交互关系的方法.

\section{The Challenge of Unstructured Modeling}

深度学习的目标是对机器学习算法进行拓展,以应对为了解决人工智能问题所要面对的挑战.

大部分使用结构化概率模型的任务对输入的结构做一个完整地理解和构建,这些任务包括
\begin{itemize}
    \item 密度估计
    \item 去噪
    \item 缺失值填充
    \item 采样
\end{itemize}

直接使用表格法存储各个随机变量间的交互情况并不可行,原因有
\begin{itemize}
    \item 内存限制
    \item 统计效率
    \item 推断代价
    \item 采样代价
\end{itemize}
但是在实际上,各个变量子集间的影响是间接的.结构化概率模型只关注随机变量间的\textbf{直接关系}.

\section{Using Graphs to Describe Model Structure}

图模型可以分为\textit{有向无环图}与\textit{无向图}两类.

\subsection{Directed Models}

有向图的边是有向的,体现在概率分布上就是条件概率分布.

只要每个变量在图中只有一小部分父节点,那么联合分布就可以使用少量的参数进行表示.

需要注意的是,有向图仅仅对相互间条件独立的变量有简化作用.

\subsection{Undirected Models}

无向图的边是没有指向的,图模型中的边与条件概率无关.

无向图模型中的\textit{因子}(factor)或者说\textit{团势}(clique potential)$\phi(\mathcal C)$用以度量团\textit{团}(clique)$\mathcal C$中每个变量间的紧密关系.但是因子并不能保证产生一个有效的概率分布.

\subsection{The Partition Function}

为保证得到有效的概率分布,需要使用规范化因子$Z$.$\phi$必须可以让$Z$易于计算.在深度学习中,常对$Z$进行近似估计.

有向图和无向图的一个重要区别是有向图直接基于概率分布构建模型,而无向图使用$\phi$构建模型,进而转化为概率分布.

需要特别注意的是,每个变量对于相应的势函数都会有影响.

\subsection{Energy-Based Models}

许多无向图模型都是基于假设$\forall\mathbf x,\tilde p(\mathbf x)>0$构建的.一种简便的方式是使用\textit{基于能量的模型}(energy-based model)
\begin{equation}
\tilde p(\mathbf x)=\exp(-E(\mathbf x))
\end{equation}
定义模型.能量函数可以完全自由地选择,没有团势函数的限制.

能量函数中的每一项对应图中的一个团.这也被称为\textit{product of experts}.也就是说,每一个专家仅仅关注低维度内随机变量的映射,但是多个专家相乘则对更加复杂的高维度空间内的变量进行了限制.

一般情况下,更常用的是\textit{自由能量}(free energy)
\begin{equation}
\mathcal F(\mathbf x)=-\log\sum_{\mathbf h}\exp(-E(\mathbf{x,h}))
\end{equation}

\subsection{Separation and D-Separation}

由于图模型中的边对应的是变量间的直接交互,那么研究变量间间接交互(即变量间条件独立)情况就对应于图的分离.其中,有向图的分离被定义为\textit{d-separation}.

但是需要强调的是,\textbf{图并不能展现所有的独立性关系}.图不会展现出不存在的独立性关系,但是可能会无法展现出某些独立性关系.