\chapter{Practical Methodology}

在机器学习模型训练过程中,涉及到的环节有收集更多的信息,增大或者减少模型的capacity,提升模型的估计推断以及调试软件.在不同的阶段需要做出正确的选择而非盲目猜测.除此之外,还应正确使用常见的算法.实际过程可以归纳为
\begin{enumerate}
    \item 确定任务目标;
    \item 建立端到端流程;
    \item 调试模型确定结果瓶颈;
    \item 对模型做出增量改变.
\end{enumerate}

\section{Performance Metrics}

错误度量指标决定了模型训练的后续动作.首先需要明确的是不可能达到$0$错误率,错误率的下限是贝叶斯错误率.

训练数据集的规模通常也受到限制.

那么基于上述两点,如何能够预估出模型的合理表现?与之相关联的是度量指标的选择.最常见的度量指标是错误率,但是许多应用要求使用更加复杂的度量指标,如\textit{精准率},\textit{召回率},以及基于精准率和召回率的\textit{F-score}.

在一些应用中,需要模型对某些样本做出拒绝判定.这是就要引入\textit{覆盖率}(coverage)的度量指标.即模型可以做出判别的样本占全部样本的比例.

\section{Default Baseline Models}

接下来的步骤是建立端到端的系统.在根据任务内容判定是否使用AI模型后,首先根据数据集的结构选择模型类别;其次选择合适的优化算法,通常使用基于动量的SGD算法或者Adam算法;最后选择正则化方式.

除了使用上述步骤,还可以从其他类似任务建立的模型中进行借鉴.

对于是否使用无监督学习的方式,需要根据问题领域进行细分.

\section{Determining Whether to Gather More Data}

通常会优先考虑收集更多的数据而非改进学习算法.

首先需要根据训练集错误率判断是否需要增加样本;接着从测试集表现判断是否需要收集更多的样本;在确定了需要收集更多样本的结论后,最后需要确定需要收集多少样本.

如果收集样本的代价很高,就需要改善学习算法来降低泛化错误率.

\section{Selecting Hyperparamters}

超参数有两种选择方式:手工选择与自动选择.

\subsection{Manual Hyperparameter Tuning}

手动设定超参数需要对超参数与训练错误率,泛化误差,计算代价的关系有深刻的了解.

手动设定超参数的目的就在运行时间以及内存允许的前提下达到最低泛化误差.除此之外,手动设定超参数还有一个目的是为了使得模型的capacity与任务的复杂度相匹配.

一般来说,泛化错误率高有两种原因:第一种是因为模型欠拟合;第二种是由于训练误差和测试误差之间的差距较大.

按照超参数调节的优先级来说,学习率调节的优先级最高.调节学习率以外的参数要同时监控训练集和测试集.

其他的大多数参数是根据它们增大或者减少模型的capacity来设定的.

正则化只是降低测试误差的一种方式,还有其他的方式可以降低测试误差.

\subsection{Automatic Hyperparameter Optimization Algorithm}

人工设定超参数的前提是人工设定的其实范围比较接近最优解,但是这个前提并不是一直都成立.因此从理论上来说,可以设计一个优化算法自动选择超参数.但是这样就会引入新的超参数.但是新的超参数相比于原有的超参数更加容易设定.

\subsection{Grid Search}

当超参数的数量小于或等于$3$个时,通常使用网格搜索方法设定超参数.

超参数搜索的范围需要根据先验知识进行设定.

网格搜索有一个很明显的缺点就是其计算代价随着参数数目的增长呈指数级增长.

\subsection{Random Search}

相比于网格搜索,随机搜索更加易于实现,方便部署,收敛速度快.

不同于网格搜索,随机搜索中的超参数不用进行离散化或者二值化操作.

随机搜索效率较高的原因是其不用进行实验性的搜索测试.

\subsection{Model-Based Hyperparameter Optimization}

自动超参数优化算法需要计算梯度,为了避免进行梯度计算,建立验证集错误率模型,通过这个模型评估超参数的泛化误差.

Bayesian超参数优化方法很常见,但并不是一种具有普遍适用性的方法.

基于模型的超参数优化方法需要实验性测试来提取出实验中的有效信息.因此效率并不是特别高.

\section{Debugging Strategies}

机器学习模型很难进行调试,同时也很难确定出现的问题是算法的原因还是软件实现的原因.

由于算法的行为很难进行预估,这一点加剧了调试的难度.如果模型各个子模块具有自适应性,调试就会更加困难.

大多数调试策略避开了上述两项困难.

一些主要的调试策略包括:
\begin{itemize}
    \item 模型动作可视化;
    \item 最差结果可视化;
    \item 通过训练错误率和测试错误率对软件进行推断;(如果训练错误率低但是测试错误率高,那么就很有可能训练算法正常但是模型过拟合;如果训练误差和测试误差都很高,那么就很难判断软件有问题还是欠拟合.)
    \item 在小规模数据集上进行测试;
    \item 将逆传播导数与数值导数进行比对,例如将
    \begin{equation}
    f'(x)=\lim_{\epsilon\to 0}\frac{f(x+\epsilon)-f(x)}{\epsilon}
    \end{equation}
    与
    \begin{description}
        \item [finite difference] \begin{equation}f'(x)\approx\frac{f(x+\epsilon)-f(x)}{\epsilon}\end{equation}
        \item [centered difference] \begin{equation}f'(x)\approx\frac{f(x+\frac{1}{2}\epsilon)-f(x-\frac{1}{2}\epsilon)}{\epsilon}\end{equation}
    \end{description}
    进行对比.此外还有对向量以及对复数的比对.
    \item 监控激活函数和梯度的直方图.
\end{itemize}

深度学习的算法还提供了一些对结果的保证.