\chapter{Practical Methodology}

在机器学习模型训练过程中,涉及到的环节有收集更多的信息,增大或者减少模型的capacity,提升模型的估计推断以及调试软件.在不同的阶段需要做出正确的选择而非盲目猜测.除此之外,还应正确使用常见的算法.实际过程可以归纳为
\begin{enumerate}
    \item 确定任务目标;
    \item 建立端到端流程;
    \item 调试模型确定结果瓶颈;
    \item 对模型做出增量改变.
\end{enumerate}

\section{Performance Metrics}

错误度量指标决定了模型训练的后续动作.首先需要明确的是不可能达到$0$错误率,错误率的下限是贝叶斯错误率.

训练数据集的规模通常也受到限制.

那么基于上述两点,如何能够预估出模型的合理表现?与之相关联的是度量指标的选择.最常见的度量指标是错误率,但是许多应用要求使用更加复杂的度量指标,如\textit{精准率},\textit{召回率},以及基于精准率和召回率的\textit{F-score}.

在一些应用中,需要模型对某些样本做出拒绝判定.这是就要引入\textit{覆盖率}(coverage)的度量指标.即模型可以做出判别的样本占全部样本的比例.

\section{Default Baseline Models}

接下来的步骤是建立端到端的系统.在根据任务内容判定是否使用AI模型后,首先根据数据集的结构选择模型类别;其次选择合适的优化算法,通常使用基于动量的SGD算法或者Adam算法;最后选择正则化方式.

除了使用上述步骤,还可以从其他类似任务建立的模型中进行借鉴.

对于是否使用无监督学习的方式,需要根据问题领域进行细分.

\section{Determining Whether to Gather More Data}

通常会优先考虑收集更多的数据而非改进学习算法.

首先需要根据训练集错误率判断是否需要增加样本;接着从测试集表现判断是否需要收集更多的样本;在确定了需要收集更多样本的结论后,最后需要确定需要收集多少样本.

如果收集样本的代价很高,就需要改善学习算法来降低泛化错误率.

\section{Selecting Hyperparamters}

超参数有两种选择方式:手工选择与自动选择.