\chapter{Approximate Inference}

概率模型训练的难点在于推断.推断的目的是为了求得\textbf{目标变量的边际分布}或者\textbf{以某些可观测变量为条件的条件分布}.深度学习中推断问题比较困难是由于隐变量间存在交互关系.

\section{Inference as Optimization}

精确推断可以归结为一个优化问题,而近似推断则是精确推断的估计.

假设概率模型包含可观测变量$\mathbf v$和隐变量$\mathbf h$,我们的目的是计算可观测变量的对数概率$\log\,p(\mathbf v;\theta)$.在有些情况下边际化$\mathbf h$很困难,可以计算$\log\,p(\mathbf v;\theta)$的下限$\mathcal L(\mathbf v,\theta,q)$,即\textit{evidence lower bound}(ELBO).ELBO的另一个更常见的名称是\textit{negative variation free energy}.
\begin{equation}
\mathcal L(\mathbf v,\theta,q)=\log\,p(\mathbf v;\theta)-D_{KL}\Big(q(\mathbf{h|v})\big\|p(\mathbf{h|v;\theta})\Big)
\end{equation}
其中$q$是关于$h$的任意分布.

因此我们可以通过最大化$\mathcal L$逼近真实分布进行推断.也可以通过控制$\mathcal L$的松紧程度灵活控制计算量.

\section{Expectation Maximization}

\textit{Expectation maximization}(EM)算法是一种基于最大化$\mathcal L$的推断算法.它适用于训练包含隐变量的模型.但它并不是近似推断的方法,而是学习近似后验概率的方法.

EM算法可以分两步,第一步通过选择分布$q$来最大化$\mathcal L$;第二步通过选择$\theta$来最大化$\mathcal L$\footnote{具体算法步骤可见原书P$634$页下方.}.

EM算法有两点本质:
\begin{enumerate}
    \item 学习过程有一个基本的结构,那就是通过更新模型参数来提升完备数据集的似然度,其中所有的缺失变量可以通过后验概率进行估计填充;
    \item 在EM算法中,我们在更新了$\theta$值之后,仍然可以沿用同一个$q$的值进行训练.
\end{enumerate}

\section{MAP Inference and Sparse Coding}

推断也可以指计算条件概率的过程.另外一种推断是计算出缺失变量的一个最可能的取值,而不是推断出在所有可能取值上的概率分布,即
\begin{equation}
\mathbf h^\ast={\arg\max}_{\mathbf h}p(\mathbf{h|v})
\end{equation}
这又被称为\textit{最大后验概率推断}(maximum a posteriori inference, MAP inference).

通常我们并不将MAP推断视为一种近似推断,因为它并不能准确地计算$\mathbf h^\ast$.如果基于最大化$\mathbf L$的策略进行学习,那么可以视为MAP提出了一个$q$值.从这种程度上来看,MAP推断是一种近似推断,因为它并不能提供最优分布$q$.

MAP推断在深度学习领域既被视为一种特征提取器,又被视为一种学习机制.它主要被用于稀疏编码模型中.

\section{Variational Inference and Learning}

\textit{变分学习}(variational learning)的核心思想是通过限制$q$的分布族来最大化$\mathcal L$.通常$q$分布相对简单或者具有良好的结构.

最常见的$q$的限制是
\begin{equation}
q(\mathbf{h|v})=\prod_iq(h_i|\mathbf v)
\end{equation}
即$q$为乘积分布.这也就是常说的\textit{平均场}(mean field)方法.更一般的,可以使用任何图模型结构来代表$q$,这种通用图模型方法被称为\textit{结构化变分推断}(structured variational inference)\footnote{什么是结构化变分推断?怎样从学习到推断?}

变分方法的一大优势是我们不需要特别指定$q$的参数化形式.即使当隐变量是离散情形时,并不需要变分法,但是变分法仍然是变分学习或者变分推断的名称来源.

\subsection{Discrete Latent Variables}

隐变量是离散情形的变分推断方法相对直观.基于平均场的方法定义分布$q$,建立查找表,通过查表法确定$q(\mathbf{h|v})$分布.

在确定$q$的形式后就需要优化其参数.由于优化过程出现在学习过程的内循环中,所以要求优化算法的收敛速度要快.\footnote{变分推断具体可见周志华所著的机器学习相关章节,这里略过.}

\subsection{Calculus of Variations}

\textit{变分法}(calculus of variations)寻求极值函数,使泛函取得极值,是处理函数的领域.

在机器学习领域中,我们通常会求取使得$J(\theta)$取得极小值的$\theta$.同样的,在某些情况下,我们的目标是求取使得$J(f(\mathbf x))$取得极小值的函数$f(\mathbf f)$,这就是变分法的应用场景.

一个方程的方程被称为\textit{泛函}(functional)$J[f]$.泛函对应于任意一个取值$\mathbf x$的$f(\mathbf x)$的导数被称为\textit{泛函导数}(functional derivatives)或者\textit{变分导数}(variational derivatives),记为$\frac{\delta}{\delta\,f(x)}J$.

对于可微函数$f(\mathbf x)$和具有连续导数的可微函数$g(y,\mathbf x)$,有
\begin{equation}
\frac{\delta}{\delta\,f(x)}\int g(f(\mathbf x),\mathbf x)d\mathbf x=\frac{\delta}{\delta\,y}g(f(\mathbf x),\mathbf x)
\end{equation}

我们可以在泛函导数为$0$的点的集合内取得泛函优化问题的最优值\footnote{优化过程举例见原书P$646$-$648$.}.

\subsection{Continuous Latent Variables}

当图模型中包含有连续隐变量时,我们希望仍然可以使用变分推断以及变分学习的方式来最大化$\mathcal L$.但是,由于隐变量是连续的,所以不能像离散情形那样对每个离散值分别进行求导.

\subsection{Interactions between Learning and Inference}