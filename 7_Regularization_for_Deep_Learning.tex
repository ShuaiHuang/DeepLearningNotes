\chapter{Regularization for Deep Learning}

正则化项主要用来降低测试误差,借以提升模型的泛化能力,是机器学习领域内的一个重要研究方向.本章的正则化特指为了降低泛化误差而对学习算法进行的修改.正则化项有两种作用方式:对先验知识进行编码;降低模型复杂度.深度学习中使用的正则化策略绝大部分是基于正则化估计量的策略.学习算法训练出的模型可能会出现
\begin{enumerate}
    \item 将真实数据生成过程排除在模型外;
    \item 符合真实的数据生成过程;\label{enum:2}
    \item 包含了真实的数据生成过程,但是也包含了其他可能的生成过程.\label{enum:3}
\end{enumerate}
正则化的目的就是将上述情况\ref{enum:3}转化为情况\ref{enum:2}.在深度学习的场景中,与真实情况最匹配的模型可能是一个包含正则化项的复杂模型.

\section{Parameter Norm Penalties}

正则化出现的时间比深度学习要早,通过在\textit{目标函数}(objective function)$J$中添加\textit{范数补偿}(norm penalty)$\Omega(\theta)$达到限制模型capacity的目的.正则化后的目标函数为
\begin{equation}\label{eq:cost_func}
\tilde J(\theta;\mathbf{X,y})=J(\theta;\mathbf{X,y})+\alpha\Omega(\theta)
\end{equation}
其中$\alpha\in[0,\infty)$是平衡正则化项权重的超参数.在深度学习中,可以对神经网络的每一层分别设置参数$\alpha$,但是这样计算代价太大,通常将所有层的参数设置成相同的.

\subsection{$L^2$ Parameter Regularization}

$L^2$正则化又被称为\textit{岭回归}(ridge regression)或者\textit{Tikhonov正则化}(Tikhonov regularization).其定义为
\begin{equation}
\tilde J(\mathbf w;\mathbf{X,y})=J(\mathbf w;\mathbf{X,y})+\frac{\alpha}{2}\mathbf w^T\mathbf w
\end{equation}
对应的权重$\mathbf w$更新公式为
\begin{equation}
\mathbf w\leftarrow(1-\epsilon\alpha)\mathbf w-\epsilon\nabla_{\mathbf w}J(\mathbf {w;X,y})
\end{equation}
可以看出正则化对于单步优化的影响为减小了步长.

通过对$J$在点$\mathbf w^\ast={\arg\min}_\mathbf wJ(\mathbf w)$做二次展开,并加上正则化项求导,设在$\tilde{\mathbf w}$导数为0,有
\begin{equation}\begin{split}
\tilde{\mathbf w}&=(\mathbf H+\alpha\mathbf I)^{-1}\mathbf{Hw}^\ast\\
&=\mathbf Q(\mathbf\Lambda+\alpha\mathbf I)^{-1}\mathbf\Lambda\mathbf Q^T\mathbf w^\ast
\end{split}\end{equation}
可以看出,与$\mathbf H$的第$i$个特征向量对应的$\mathbf w^\ast$缩小比例为$\frac{\lambda_i}{\lambda_i+\alpha}$.当$\lambda_i\gg\alpha$时,正则化影响很小;当$\lambda_i\ll\alpha$时,缩小至$0$附近.也就是说,正则化项只有对目标函数下降比较明显的方向上的分量才会做完整的保留.

对线性回归问题,正则化项加上均方误差为
\begin{equation}
\mathbf{(Xw-y)^T(Xw-y)}+\frac{1}{2}\alpha\mathbf{w^Tw}
\end{equation}
对应的对$\mathbf w$导数为$0$的点为
\begin{equation}
\mathbf{w=(X^TX}+\alpha\mathbf{I)^{-1}X^Ty}
\end{equation}
正则化项对输入中方差较高项进行了保留.

\subsection{$L^1$ Regularization}\label{sec:l1_regularization}

$L^1$正则化项被定义为
\begin{equation}
\Omega(\theta)=\|\mathbf w\|_1=\sum_i|w_i|
\end{equation}
相应的目标函数为
\begin{equation}
\tilde J(\mathbf{w;X,y})=\alpha\|\mathbf w\|_1+J(\mathbf{w;X,y})
\end{equation}
正则化项对于梯度的贡献只有符号.为了简化对$1$-范数求导,假设Hessian矩阵是对角矩阵$\mathbf H=diag([H_{1,1},\cdots,H_{n,n}])$,其中$H_{i,i}>0$.有
\begin{equation}
\hat J(\mathbf{w;X,y})=J(\mathbf{w^\ast;X,y})+\sum_i\Big[\frac{1}{2}H_{i,i}(\mathbf{w_i-w_i^\ast})^2+\alpha|w_i|\Big]
\end{equation}
极小值为
\begin{equation}
w_i=\text{sign}(w_i^\ast)\max\{|w_i^\ast|-\frac{\alpha}{H_{i,i}},0\}
\end{equation}
可以看出,$L^1$正则化让解更稀疏.所以它常被用来作特征选择.

此外,$L^2$正则化等价于高斯先验的MAP贝叶斯推断;$L^1$正则化等价于各向同性Laplace分布先验的MAP贝叶斯推断\footnote{正则化项等价于式\ref{eq:map_estimation}中的$\log p(\theta)$项,即将参数的先验分布整合进目标函数中进行优化.但并不是所有的正则化项都等价于MAP贝叶斯推断.}.

\section{Norm Penalties as Constrained Optimization}

在前一节中提到的式\ref{eq:cost_func}中的优化问题可以通过Lagrangian函数转化为有限制条件的优化问题
\begin{equation}\label{eq:explicit_constrain}
\mathcal L(\theta,\alpha;\mathbf{X,y})=J(\theta;\mathbf{X,y})+\alpha(\Omega(\theta)-k)
\end{equation}
相应的,解为
\begin{equation}
\theta^\ast={\arg\min}_\theta\max_{\alpha,\alpha\ge 0}\mathcal L(\theta,\alpha)
\end{equation}
定性地分析,最优值$\alpha^\ast$会使$\Omega(\theta)$的值不断减小,但还没有到达让$\Omega(\theta)$小于$k$的程度.因此,我们可以将范数补偿视为在目标函数上增加限制条件.如果不知道限制区域的大小,可以通过调节$\alpha$对限制区域的大小进行调节.

上述显式限制条件有两个优点
\begin{itemize}
    \item 如果知道限制条件,即式\ref{eq:explicit_constrain}中$k$的数值,那么可以直接对$J(\theta)$使用梯度下降法求下降方向,然后在最小值点附近寻找满足$\Omega(\theta)<k$的点.这种reprojection过程就避免了搜索与$k$相匹配的$\alpha$的过程;
    \item 显式限制条件可以避免隐式限制条件因为引入补偿项而导致的非凸优化过程陷入局部极小点.而reprojection方法可以避免这种现象;
    \item 增加优化过程的稳定性,避免因为学习率参数较高导致的权重参数溢出.
\end{itemize}

在实际中,常将\textit{列范数限制}(column norm limitation)与显式限制条件相结合使用.

\section{Regularization and Under-Constrained Problems}

在机器学习中,正则化项需要根据实际问题进行妥善定义,因为正则化项需要保证未定问题迭代优化过程的收敛性.

在机器学习以外的领域,也有通过添加正则化项来解决优化问题的方法,如Moore-Penrose广义逆.

\section{Dataset Augmentation}

在机器学习中,可以通过创造"假"数据的方法来增大数据集.这种方法适用于分类问题,但是在其他领域内不太适用,因为可能会改变数据的原始分布.

Dataset augmentation对物体识别问题特别有效.需要注意的是,dataset augmentation不能改变样本的真实标记.

Dataset augmentation在语音识别领域也被广泛应用.

对不同算法进行性能评估比较时,必须将dataset augmentation也考虑进去,在同样的条件下进行比较.

\section{Noise Robustness}

在某些神经网络模型上,给输入添加合适的噪声等价于对权重的范数补偿.这种方法相比于限制权重的大小更加有效,特别是将噪声添加到隐层的输入上.

另外,在网络连接的权重上增加噪声也等价于对模型进行正则化.

增加噪声间接导致了模型学习出稳定的函数.

\subsection{Injection Noise at the Output Targets}

由于某些数据集中部分样本的标注不是完全正确,所以当$y$错误时,直接最大化$\log p(y|\mathbf x)$可能会出现问题.因此\textit{label smoothing}被广泛应用,它使用softmax对模型的0-1硬标记进行替换.

\section{Semi-Supervised Learning}

\textit{半监督学习}是指使用$P(\mathbf x)$中采样得到的未标记样本和从$P(\mathbf{x, y})$中得到的有标记样本共同预测$P(\mathbf{y|x})$的过程.

深度学习中半监督学习的目的是学习特征表示,这样相同类别的样本就会有相似的特征表示.

与传统的有监督学习和无监督学习分离的方法相比,半监督学习通过$P(\mathbf{x,y})$或$P(\mathbf x)$和$P(\mathbf{y|x})$共享参数的方法将两个过程进行融合.

\section{Multi-Task Learning}

多任务学习通过合并不同任务中的样本提升泛化性能.训练出的模型参数分为两类
\begin{itemize}
    \item 任务特定参数
    \item 通用参数
\end{itemize}

由于通用参数的存在,模型的泛化能力得到提升,泛化误差下降.但是多任务学习也有一项前提假设:不同的任务受到同一因素影响,并且这个因素可以通过数据观察得到.

\section{Early Stopping}

早停是指泛化误差达到最小值后,参数更新到达指定迭代次数后终止优化算法,并将参数恢复至泛化误差最小点所对应的参数.通过早停策略可以减少验证集上的误差,从而提升泛化性能.

早停是一种高效的超参数选择方法,它可以选择合适的优化算法迭代次数(超参数),并且不会对原始的算法产生影响.但是同时它也会增加计算代价和存储代价.
\begin{itemize}
    \item \textbf{计算代价}:在优化过程中,每隔一定迭代轮数,需要计算当前模型在验证集上的误差;
    \item \textbf{存储代价}:在优化过程中需要时刻保存一份最优参数.
\end{itemize}

早停策略也可以与其他正则化策略一起使用.

为了充分利用所有的训练数据,可以进行二次训练:
\begin{enumerate}
    \item 重新初始化模型,按照第一轮的超参数进行训练;
    \item 保持第一轮的最优参数,加入新的数据继续进行训练.
\end{enumerate}

从本质上来说,早停将超参数限制在初始值附近的空间中.在一定条件下,早停与$L^2$正则化等价.但是从优化过程上来看,早停自动决定了正则化程度,而$L^2$正则化需要调整超参数.

\section{Parameter Tying and Parameter Sharing}

有时我们需要将正则化之外的先验条件整合到模型中去.此外,我们可以知道模型的结构和相关领域的知识,这样模型之间的参数可能会有一些从属关系(dependency).最常见的模型间的参数从属关系是共享参数.

共享参数的一个重要优势是其存储优势,从而借助于共享参数,可以在不增加样本的情况下提升网络的层数.\footnote{CNN网络中,不同位置的出现的特征共享参数,可以在物体检测任务中得到与空间无关的结果.}

\section{Sparse Representation}

另一种正则化方法是对激活函数添加补偿项使其输出稀疏化.表示方法正则化与参数正则化的机制一致,即
\begin{equation}
\tilde J(\theta;\mathbf{X,y})=J(\theta;\mathbf{X,y})+\alpha\Omega(\mathbf h)
\end{equation}
其中,$\Omega(\mathbf h)$不仅仅可以使用\ref{sec:l1_regularization}节中提到的$L^1$正则补偿项的形式,还可以借助于其他的一些形式实现稀疏化表达.

除了上述添加补偿项实现表示稀疏,还可以通过在激活值上添加硬限制条件实现稀疏表达.典型的方法有\textit{orthogonal matching pursuit}.

从理论上来说,任何有隐层的模型都可以进行稀疏化表示.

\section{Bagging and Other Ensemble Methods}

Bagging是一种集成学习方法,它在不同的训练集上分别训练出不同的模型,对测试样本进行投票得到最终结果,以降低泛化误差.从整体上来看,集成学习器至少和它当中的任何一个学习器表现相当,如果学习器间的误差相互独立,则它的表现将会比其中任何一个学习器都要好.通常学习器会通过不同的学习方法生成,即不同的算法,不同的目标函数以及不同的模型.特别地,通过有放回采样获得$k$个不同的数据子集,在数据子集上分别训练出不同的模型.

由于神经网络参数经过训练后点分布范围比较广泛,所以通常在同一个数据集上进行训练,并将训练完成的模型进行集成.

集成学习是一种极其有效且可靠地降低泛化错误率的方法.但是它的计算和存储开销很大.需要注意的是,并不是所有的集成学习都是为了提升正则化能力,例如Boosting就是为了提升模型的capacity.

\section{Dropout}

Dropout为各种模型提供便于计算的正则化方法.特别地,它为神经网络提供了一种低计算开销的集成方法.具体来说,dropout依次去除原始神经网络中的非输出单元,形成模型子集.子集中模型的数量与神经单元的数量呈指数级关系.为了将模型与dropout进行结合,需要使用基于minibatch的训练方法,以提取出指数级数量的训练子集.

Dropout模型的损失函数定义为
\begin{equation}
\mathbb E_{\mathbf\mu}J(\theta;\mathbf\mu)
\end{equation}
其中,$\mathbf\mu$是\textit{mask vector},用以指定被包含进子模型的神经单元;$J(\theta;\mathbf\mu)$定义了基于模型参数$\theta$和$\mathbf\mu$的损失函数.

Dropout与bagging的不同之处在于
\begin{itemize}
    \item Bagging中学习器间相互独立;而dropout各个子模型之间的参数是共享的;
    \item Bagging中各个学习器经过训练都会达到收敛状态;而dropout大部分子模型都没有被充分地训练(由于参数共享,可以保证模型有较高的泛化能力).
\end{itemize}

集成学习中的Bagging模型需要将所有子模型对新样本的预测结果收集起来进行综合判断,这一个过程被称为\textit{推断}(inference).特别地,针对dropout算法,需要首先建立起计算模型
\begin{equation}
\sum_{\mathbf\mu}p(\mathbf\mu)p(y|\mathbf{x,\mu})
\end{equation}
其中$p(\mathbf\mu)$是训练时mask vector的概率密度函数.其次在实际中,只需要对$\mathbf\mu$进行采样就可以近似估计出推断结果.

尽管采样可以近似估计出推断结果,但是还有更好的推断方式:使用几何平均数代替算术平均数.
\begin{equation}
\tilde p_{ensemble}(y|\mathbf x)=\sqrt[2^d]{\prod_{\mathbf\mu}p(y|\mathbf{x,\mu})}
\end{equation}
进行归一化,有
\begin{equation}
p_{ensemble}(y|\mathbf x)=\frac{\tilde p_{ensemble}(y|\mathbf x)}{\sum_{y'}\tilde p_{ensemble}(y'|\mathbf x)}
\end{equation}
这种推断方式被称为\textit{weighted scaling inference rule}.

需要注意的是,我们通常将\textit{包含概率}\footnote{The probability becoming part of the sample during the drawing of a single sample.}(inclusion probability)设为$\frac{1}{2}$,所以所以需要在训练过程结束后将神经元的连接权重除以$2$.也可以在训练过程中将每个神经元的状态(states)乘$2$\footnote{TODO: figure it out.}.

实验证明, weighted scaling inference rule与蒙特卡洛估计相比,各有好坏,需要根据实际情况选择最优的策略.但是总体来说, weighted scaling inference rule的优势有
\begin{itemize}
    \item 计算效率高,可以与其他形式的正则化方法结合使用;
    \item 计算代价低;
    \item 对模型和训练过程几乎没有影响.
\end{itemize}
同时,也需要认识到它的劣势
\begin{itemize}
    \item effective capacity受限,为了解决这个问题,需要增大模型的规模;
    \item dropout在小规模数据集上的表现不好.
\end{itemize}

前面提到的dropout的随机性并不是dropout方法有效的关键,随机性仅仅是一种估计的手段.\textit{fast drop}方法就是通过减少梯度计算时的随机性来加速算法收敛的.另外, dropout的随机性对其正则化的作用也不充分.

Dropout催生出了许多正则化方法,它们都借助于指数级别的子模型来共享参数.因此,dropout是迄今为止应用最为广泛的集成学习方法.

Dropout本质上是一种共享参数的bagging方法.所以, dropout的mask并不一定是严格的$0$-$1$分布,它也可以是诸如$\mathcal N(1,\mathbf I)$的正态分布.

dropout还是隐层单元共享参数的方法.它通过随机屏蔽隐层单元,使得学习到的特征更具有鲁棒性.本质上来说, dropout可视为神经元输入信息的损失,而非原始信息的损失.相比之下,传统的噪声注入并不能有效抹除上下文相关信息. Dropout充分利用分布表达的优势,充分利用上下文信息.

同时从另外一方面来说, dropout会使噪声加倍,如果噪声过大的话,就没必要使用dropout进行正则化了.

\section{Adversarial Training}

如果想要评估高精度模型对任务的理解程度,就需要特别关注误分样本和\textit{对立样本}(adversarial example).同时,还可以借助于对立样本对训练集的扰动对模型进行\textit{对立训练}(adversarial training),以降低测试误差.

对立样本产生的原因是因为模型过度线性化.对立训练使模型在训练样本周围达到局部平坦,从而避免模型因局部线性而对扰动特别敏感的特性.

对立训练有助于提升函数族强大的正则化能力.

对立样本还有助于完成半监督学习.假设不同类别的样本分布于不连通的流形上,一个很小的扰动不会使得样本从其所在的流形跳到其他流形上.

\section{Tangent Distance, Tangent Prop, and Manifold Tangent Classifier}

\textit{切面距离算法}(tangent distance algorithm)是一种非参数最近邻算法.与最近邻算法不同的是,它使用的是流形距离.即假设不同类别的样本分别位于不同的流形上,两个不同类别的样本间的距离需要通过优化问题进行求解.为了简化距离计算,可以将两个样本在流形上的切面间的距离作为样本间的距离.

在此基础上,\textit{切面传播算法}(tangent prop algorithm)训练出一个神经网络分类器,并在其损失函数上添加补偿项
\begin{equation}
\Omega(f)=\sum_i\Big((\nabla_{\mathbf x}f(\mathbf x))^T\mathbf v^{(i)}\Big)^2
\end{equation}
使得$f(\mathbf x)$对已知的变量不敏感.补偿项就包含了先验知识,使得输出函数在训练样本附近平坦. Tangent prop算法不仅被用于有监督学习,还被用于强化学习.

Tangent prop与data augmentation相比,它们的相同之处为:编码先验知识,使得输入有扰动时,输出不变.不同之处在于
\begin{itemize}
    \item data augmentation中,对输入样本做多种转换,保持输出正确;而tangent prop只做输出局部平坦的先验,并不要求输出达到新的点;
    \item tangent prop的较少种类的扰动对rectified单元求导造成了困难;而data augmentation由于扰动种类较多,所以斌不会对rectified单元求导造成太大苦难.
\end{itemize}

Tangent prop与double backprop\footnote{A new training algorithm termed double backpropagation improves generalization by simultaneously minimizing the normal energy term found in backpropagation and an additional energy term that is related to the sum of the squares of the input derivatives (gradients).}以及对立学习很相似.
\begin{itemize}
    \item Double backprop通过正则化将Jacobian\footnote{见\pageref{eq:jacobian_matrix}页式\ref{eq:jacobian_matrix}.}变得很小,对立训练通过对输入增加扰动,使模型输出不变;
    \item Tangent prop与data augmentation都使得输入有扰动时,输出不变;
    \item Double backprop和对立训练都要求输入样本在所有方向上有扰动时,输出的变化很小;
    \item Data augmentation相比于tangent prop,输入变换的种类较多;
    \item 对立训练相比于double backprop,变换的方式有很多.
\end{itemize}

\textit{流形切面分类器}(manifold tangent classifier)避免了使用流形的切向量作为先验知识的麻烦.它的算法很简单
\begin{enumerate}
    \item 使用autoencoder模型,无监督学习流行的结构;
    \item 使用切面正则化神经网络分类器(参考tangent prop算法).
\end{enumerate}