\chapter{Regularization for Deep Learning}

正则化项主要用来降低测试误差,借以提升模型的泛化能力,是机器学习领域内的一个重要研究方向.本章的正则化特指为了降低泛化误差而对学习算法进行的修改.正则化项有两种作用方式:对先验知识进行编码;降低模型复杂度.深度学习中使用的正则化策略绝大部分是基于正则化估计量的策略.学习算法训练出的模型可能会出现
\begin{enumerate}
    \item 将真实数据生成过程排除在模型外;
    \item 符合真实的数据生成过程;\label{enum:2}
    \item 包含了真实的数据生成过程,但是也包含了其他可能的生成过程.\label{enum:3}
\end{enumerate}
正则化的目的就是将上述\ref{enum:3}中的情况转化为\ref{enum:2}的情况.在深度学习的场景中,与真实情况最匹配的模型可能是一个包含正则化项的复杂模型.

\section{Parameter Norm Penalties}

正则化出现的时间比深度学习要早,通过在\textit{目标函数}(objective function)$J$中添加\textit{范数补偿}(norm penalty)$\Omega(\theta)$达到限制模型capacity的目的.正则化后的目标函数为
\begin{equation}\label{eq:cost_func}
\tilde J(\theta;\mathbf{X,y})=J(\theta;\mathbf{X,y})+\alpha\Omega(\theta)
\end{equation}
其中$\alpha\in[0,\infty)$是平衡正则化项权重的超参数.在深度学习中,可以对神经网络的每一层分别设置参数$\alpha$,但是这样计算代价太大,通常将每一层的参数设置成相同的.

\subsection{$L^2$ Parameter Regularization}

$L^2$正则化又被称为\textit{岭回归}(ridge regression)或者\textit{Tikhonov正则化}(Tikhonov regularization).其定义为
\begin{equation}
\tilde J(\mathbf w;\mathbf{X,y})=J(\mathbf w;\mathbf{X,y})+\frac{\alpha}{2}\mathbf w^T\mathbf w
\end{equation}
对应的权重$\mathbf w$更新公式为
\begin{equation}
\mathbf w\leftarrow(1-\epsilon\alpha)\mathbf w-\epsilon\nabla_{\mathbf w}J(\mathbf {w;X,y})
\end{equation}
可以看出正则化对于单步优化的影响为减小了步长.

通过对损失函数在点$\mathbf w^\ast={\arg\min}_\mathbf wJ(\mathbf w)$做二次展开,并求展开式对$\mathbf w$的导数,设在$\tilde{\mathbf w}$导数为0,有
\begin{equation}\begin{split}
\tilde{\mathbf w}&=(\mathbf H+\alpha\mathbf I)^{-1}\mathbf{Hw}^\ast\\
&=\mathbf Q(\mathbf\Lambda+\alpha\mathbf I)^{-1}\mathbf\Lambda\mathbf Q^T\mathbf w^\ast
\end{split}\end{equation}
可以看出,与$\mathbf H$的第$i$个特征向量对应的$\mathbf w^\ast$缩小比例为$\frac{\lambda_i}{\lambda_i+\alpha}$.当$\lambda_i\gg\alpha$时,正则化影响很小;当$\lambda_i\ll\alpha$时,缩小至$0$附近.也就是说,正则化项只有对目标函数下降比较明显的方向上的分量才会做完整的保留.

对线性回归问题,正则化项加上均方误差为
\begin{equation}
\mathbf{(Xw-y)^T(Xw-y)}+\frac{1}{2}\alpha\mathbf{w^Tw}
\end{equation}
对应的对$\mathbf w$导数为$0$的点为
\begin{equation}
\mathbf{w=(X^TX}+\alpha\mathbf{I)^{-1}X^Ty}
\end{equation}
正则化项对输入中方差较高项进行了保留.

\subsection{$L^1$ Regularization}\label{sec:l1_regularization}

$L^1$正则化项被定义为
\begin{equation}
\Omega(\theta)=\|\mathbf w\|_1=\sum_i|w_i|
\end{equation}
相应的目标函数为
\begin{equation}
\tilde J(\mathbf{w;X,y})=\alpha\|\mathbf w\|_1+J(\mathbf{w;X,y})
\end{equation}
正则化项对于梯度的贡献只有符号.为了简化对$1$-范数求导,假设Hessian矩阵是对角矩阵$\mathbf H=diag([H_{1,1},\cdots,H_{n,n}])$,其中$H_{i,i}>0$.有
\begin{equation}
\hat J(\mathbf{w;X,y})=J(\mathbf{w^\ast;X,y})+\sum_i\Big[\frac{1}{2}H_{i,i}(\mathbf{w_i-w_i^\ast})^2+\alpha|w_i|\Big]
\end{equation}
极小值为
\begin{equation}
w_i=\text{sign}(w_i^\ast)\max\{|w_i^\ast|-\frac{\alpha}{H_{i,i}},0\}
\end{equation}
可以看出,$L^1$正则化让解更稀疏.所以它常被用来作特征选择.

此外,$L^2$正则化等价于高斯先验的MAP贝叶斯推断;$L^1$正则化等价于各向同性Laplace分布先验的MAP贝叶斯推断\footnote{TODO:复习与MAP贝叶斯推断的等价关系}.

\section{Norm Penalties as Constrained Optimization}

在前一节中提到的式\ref{eq:cost_func}中的优化问题可以通过Lagrangian函数转化为有限制条件的优化问题
\begin{equation}\label{eq:explicit_constrain}
\mathcal L(\theta,\alpha;\mathbf{X,y})=J(\theta;\mathbf{X,y})+\alpha(\Omega(\theta)-k)
\end{equation}
相应的,解为
\begin{equation}
\theta^\ast={\arg\min}_\theta\max_{\alpha,\alpha\ge 0}\mathcal L(\theta,\alpha)
\end{equation}
定性地分析,最优值$\alpha^\ast$会使$\Omega(\theta)$的值不断减小,但还没有到达让$\Omega(\theta)$小于$k$的程度.因此,我们可以将范数补偿视为在目标函数上增加限制条件.如果不知道限制区域的大小,可以通过调节$\alpha$对限制区域的大小进行调节.

上述显式限制条件有两个优点
\begin{itemize}
    \item 如果知道限制条件,即式\ref{eq:explicit_constrain}中的$k$,那么可以直接对$J(\theta)$使用梯度下降法求下降方向,然后在最小值点附近寻找满足$\Omega(\theta)<k$的点.这样就避免了搜索与$k$相匹配的$\alpha$的过程;
    \item 显式限制条件可以避免因为引入补偿项而导致的非凸优化过程陷入局部极小点.而reprojection方法可以避免这种现象;
    \item 增加优化过程的稳定性.
\end{itemize}

在实际中,常将\textit{列范数限制}(column norm limitation)与显式限制条件相结合使用.

\section{Regularization and Under-Constrained Problems}

在机器学习中,正则化项需要根据实际问题进行妥善定义,因为正则化项需要保证未定问题迭代优化过程的收敛性.

在机器学习以外的领域,也有通过添加正则化项来解决优化问题的方法,如Moore-Penrose广义逆.

\section{Dataset Augmentation}

在机器学习中,可以通过创造"假"数据的方法来增大数据集.这种方法适用于分类问题,但是在其他领域内不太适用,因为可能会改变数据的原始分布.

Dataset augmentation对物体识别问题特别有效.需要注意的是,dataset augmentation不能改变样本的真实标记.

Dataset augmentation在语音识别领域也被广泛应用.

对不同算法进行性能评估比较时,必须将dataset augmentation也考虑进去,在同样的条件下进行比较.

\section{Noise Robustness}

在某些神经网络模型上,给输入添加合适的噪声等价于对权重的范数补偿.这种方法相比于限制权重的大小更加有效,特别是将噪声添加到隐层的输入上.

另外,在网络连接的权重上增加噪声也等价于对模型进行正则化.

增加噪声间接导致了模型学习出稳定的函数.

\subsection{Injection Noise at the Output Targets}

由于某些数据集中部分样本的标注不是完全正确,所以当$y$错误时,直接最大化$\log p(y|\mathbf x)$可能会出现问题.因此\textit{label smoothing}被广泛应用,它使用softmax对模型的0-1硬标记进行替换.

\section{Semi-Supervised Learning}

\textit{半监督学习}是指使用$P(\mathbf x)$中采样得到的未标记样本和从$P(\mathbf{x, y})$中得到的有标记样本共同预测$P(\mathbf{y|x})$的过程.

深度学习中半监督学习的目的是学习特征表示,这样相同类别的样本就会有相似的特征表示.

与传统的有监督学习和无监督学习分离的方法相比,半监督学习通过$P(\mathbf{x,y})$或$P(\mathbf x)$和$P(\mathbf{y|x})$共享参数的方法将两个过程进行融合.

\section{Multi-Task Learning}

多任务学习通过合并不同任务中的样本提升泛化性能.训练出的模型参数分为两类
\begin{itemize}
    \item 任务特定参数
    \item 通用参数
\end{itemize}

由于通用参数的存在,模型的泛化能力得到提升,泛化误差下降.但是多任务学习也有一项前提假设:不同的任务受到同一因素影响,并且这个因素可以通过数据观察得到.

\section{Early Stopping}

早停是指泛化误差达到最小值后,参数更新到达指定迭代次数后终止优化算法,并将参数恢复至泛化误差最小点所对应的参数.通过早停策略可以减少验证集上的误差,从而提升泛化性能.

早停是一种高效的超参数选择方法,它可以选择合适的优化算法迭代次数(超参数),并且不会对原始的算法产生影响.但是同时它也会增加计算代价和存储代价.
\begin{itemize}
    \item \textbf{计算代价}:在优化过程中,每隔一定迭代轮数,需要计算当前模型在验证集上的误差;
    \item \textbf{存储代价}:在优化过程中需要时刻保存一份最优参数.
\end{itemize}

早停策略也可以与其他正则化策略一起使用.

为了充分利用所有的训练数据,可以进行二次训练:
\begin{enumerate}
    \item 重新初始化模型,按照第一轮的超参数进行训练;
    \item 保持第一轮的最优参数,加入新的数据继续进行训练.
\end{enumerate}

从本质上来说,早停将超参数限制在初始值附近的空间中.在一定条件下,早停与$L^2$正则化等价.但是从优化过程上来看,早停自动决定了正则化程度,而$L^2$正则化需要调整超参数.

\section{Parameter Tying and Parameter Sharing}

有时我们需要将正则化之外的先验条件整合到模型中去.此外,我们可以知道模型的结构和相关领域的知识,这样模型之间的参数可能会有一些从属关系(dependency).最常见的模型间的参数从属关系是共享参数.

共享参数的一个重要优势是其存储优势,从而借助于共享参数,可以提升网络的层数.\footnote{TODO: 仔细理解共享参数.CNN是如何实现共享参数的?}

\section{Sparse Representation}

另一种正则化方法是对激活函数添加补偿项使其输出稀疏化.表示方法正则化与参数正则化的机制一致,即
\begin{equation}
\tilde J(\theta;\mathbf{X,y})=J(\theta;\mathbf{X,y})+\alpha\Omega(\mathbf h)
\end{equation}
其中,$\Omega(\mathbf h)$不仅仅可以使用\ref{sec:l1_regularization}节中提到的$L^1$正则补偿项的形式,还可以借助于其他的一些形式实现稀疏化表达.

除了上述添加补偿项实现表示稀疏,还可以通过在激活值上添加硬限制条件实现稀疏表达.典型的方法有\textit{orthogonal matching pursuit}.

从理论上来说,任何有隐层的模型都可以进行稀疏化表示.